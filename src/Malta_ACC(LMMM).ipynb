{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from complexity.airspace import airspace\n",
    "from traffic.data import nm_airspaces\n",
    "from utils import viz as viz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining airspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deinition of airspace\n",
    "lmmm = airspace(\n",
    "    id=\"LMMM\",\n",
    "    volume = nm_airspaces['LMMMALL']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching of ADS-B data\n",
    "lmmm.data_fetch(\n",
    "    start_date=\"2019-01-01\",\n",
    "    end_date=\"2020-01-01\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing ADS-B data\n",
    "lmmm.data_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualisation of airspace and trajectories before pre-processing\n",
    "# fig1 = lsaguac.plot(traj_sample= True, traj_num=10, reduced=False)\n",
    "# fig1.show()\n",
    "# # Visualisation of airspace and trajectories after pre-processing\n",
    "# fig2 = lsaguac.plot(traj_sample= True, traj_num=10, reduced=True)\n",
    "# fig2.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification and extraction of low-traffic trajectories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring hourly traffic load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of dataframe containing hourly entry counts\n",
    "lmmm.hourly_generate_df()\n",
    "# Plotting of heatmap of entry counts\n",
    "fig = lmmm.hourly_heatmap()\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of low-traffic threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of heatmap-like plot\n",
    "fig1 = lmmm.hourly_heatmap_low(reference_type='max_perc', reference_value=0.45)\n",
    "fig1.show()\n",
    "# Generation of multiple boxplots\n",
    "fig2 = lmmm.hourly_boxplots(reference_type='max_perc', reference_value=0.45)\n",
    "fig2.show()\n",
    "# Generation of Cumulative distribution function\n",
    "fig3 = lmmm.hourly_cdf(reference_type='max_perc', reference_value=0.45)\n",
    "fig3.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmmm.reduce_low_traffic(reference_type='max_perc', reference_value=0.45)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = lsaguac.run_simulation(duration=24, interval=10, start_time='2019-01-01 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.flight_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.timestamp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower = temp[temp.flight_id == 'MSR801_110_15:31:20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "temp2 = temp[temp.timestamp < pd.Timestamp('2019-01-02 00:00:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Timestamp('2019-01-01 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + pd.Timedelta(hours=24)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2.flight_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot histogram of temp.timestamp\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.hist(temp.timestamp, bins=365)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.flight_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.timestamp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsaguac.generate_cells(dim=5, alt_diff=1000)\n",
    "# lsaguac.visualise_cells()\n",
    "lsaguac.parallel_simulation_run(duration = 24,\n",
    "                                interval = 20,\n",
    "                                runs = 10000,\n",
    "                                max_process = 50,\n",
    "                                start_num = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle load file into variable temp\n",
    "temp = pickle.load(open('/cluster/home/krum/github/VT2_airspace_complexity/data/LSAGUAC/08_monte_carlo/24_20/cubes/9408_results.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import general as util_general\n",
    "from traffic.core import Traffic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "home_path = util_general.get_project_root()\n",
    "\n",
    "num = 10 # number of simulations (monte carlo)\n",
    "duration = 24\n",
    "interval = 20\n",
    "start_time = pd.Timestamp(\"2000-01-01 00:00:00\")\n",
    "\n",
    "# Load data and get ids and dataframe\n",
    "trajs_low = Traffic.from_file(\n",
    "    f\"{home_path}/data/LSAGUAC/05_low_traffic/trajs_tma_low.parquet\"\n",
    ")\n",
    "ids = trajs_low.flight_ids\n",
    "trajs_low_data = trajs_low.data\n",
    "\n",
    "totalseconds = duration * 60 * 60\n",
    "amount_deploys = int(totalseconds / interval)\n",
    "\n",
    "timelist = []\n",
    "timer = 0\n",
    "for i in range(int(amount_deploys)):\n",
    "    timelist.append(start_time + pd.Timedelta(seconds=timer))\n",
    "    timer = timer + interval\n",
    "times = np.array(timelist)\n",
    "\n",
    "indices = np.random.default_rng().choice(\n",
    "    len(ids), len(timelist), replace=True\n",
    ")\n",
    "ids = np.array(ids)[indices]\n",
    "\n",
    "grouped = trajs_low_data.groupby(\"flight_id\")\n",
    "\n",
    "# generate simulated trajectories\n",
    "# print(\"Generating simulated trajectories...\")\n",
    "df_all = []\n",
    "\n",
    "for id, tm in zip(ids, times):\n",
    "    # traj_time = start_time + pd.Timedelta(seconds=tm)\n",
    "    temp = grouped.get_group(id)\n",
    "    timedelta = temp[\"timestamp\"] - temp[\"timestamp\"].iloc[0]\n",
    "    new_timestamp = tm + timedelta\n",
    "    timestring = str(new_timestamp.iloc[0].time())\n",
    "    flight_id = temp[\"flight_id\"].iloc[0]\n",
    "    temp = temp[[\"latitude\", \"longitude\", \"altitude\", \"icao24\"]]\n",
    "    temp.insert(0, \"timestamp\", new_timestamp)\n",
    "    temp.insert(1, \"flight_id\", flight_id + \"_\" + timestring)\n",
    "    df_all.append(temp)\n",
    "\n",
    "df_traf = (\n",
    "    pd.concat(df_all, axis=0)\n",
    "    .sort_values(by=[\"timestamp\"])\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelist[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsaguac.visualise_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsaguac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsaguac.run_simulation(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsaguac.parallel_simulation_run(duration = 24,\n",
    "                                interval = 20,\n",
    "                                runs = 10000,\n",
    "                                max_process = 50,\n",
    "                                start_num = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from traffic.core import Traffic\n",
    "from utils import general as util_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "\n",
    "home_path = util_general.get_project_root()\n",
    "\n",
    "# get list of all files in the folder\n",
    "files = glob.glob(f\"{home_path}/data/LSAGUAC/08_monte_carlo/24_120/total/*.pkl\", recursive=True)\n",
    "\n",
    "values = []\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "        values.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce values to only contain  entries below 50\n",
    "values = [x for x in values if x < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(values, bins=100)\n",
    "\n",
    "# x axis label\n",
    "plt.xlabel('Number of occurences')\n",
    "\n",
    "# plot title\n",
    "plt.title('Histogram of number of total occurences')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# get 95% confidence interval\n",
    "from scipy import stats\n",
    "\n",
    "stats.norm.interval(0.90, loc=np.mean(values), scale=np.std(values))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max value of values\n",
    "min(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = util_general.get_project_root()\n",
    "\n",
    "trajs_low = Traffic.from_file(\n",
    "            f\"{home_path}/data/LSAGUAC/05_low_traffic/trajs_tma_low.parquet\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 1\n",
    "interval = 180\n",
    "\n",
    "ids = trajs_low.flight_ids\n",
    "trajs_low_data = trajs_low.data\n",
    "\n",
    "totalseconds = duration * 24 * 60 * 60\n",
    "amount_deploys = int(totalseconds / interval)\n",
    "\n",
    "timelist = []\n",
    "\n",
    "timer = 0\n",
    "for i in range(int(amount_deploys)):\n",
    "    timelist.append(timer)\n",
    "    timer = timer + interval\n",
    "\n",
    "indices = np.random.default_rng().choice(\n",
    "    len(ids), len(timelist), replace=True\n",
    ")\n",
    "\n",
    "random_ids = np.array(ids)[indices]\n",
    "random_times = np.array(timelist)\n",
    "\n",
    "grouped = trajs_low_data.groupby(\"flight_id\")\n",
    "\n",
    "# generate simulated trajectories\n",
    "print(\"Generating simulated trajectories...\")\n",
    "df_all = []\n",
    "start_time = pd.Timestamp(\"2000-01-01 00:00:00\")\n",
    "\n",
    "for id, tm in tqdm(\n",
    "    zip(random_ids, random_times), total=len(random_ids)\n",
    "):\n",
    "    traj_time = start_time + pd.Timedelta(seconds=tm)\n",
    "    temp = grouped.get_group(id)\n",
    "    timedelta = temp[\"timestamp\"] - temp[\"timestamp\"].iloc[0]\n",
    "    new_timestamp = traj_time + timedelta\n",
    "    timestring = str(new_timestamp.iloc[0].time())\n",
    "    flight_id = temp[\"flight_id\"].iloc[0]\n",
    "    temp = temp[[\"latitude\", \"longitude\", \"altitude\", \"icao24\"]]\n",
    "    temp.insert(0, \"timestamp\", new_timestamp)\n",
    "    temp.insert(1, \"flight_id\", flight_id + \"_\" + timestring)\n",
    "    df_all.append(temp)\n",
    "\n",
    "df_traf = (\n",
    "    pd.concat(df_all, axis=0)\n",
    "    .sort_values(by=[\"timestamp\"])\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import general as util_general\n",
    "from traffic.core import Traffic\n",
    "\n",
    "home_path = util_general.get_project_root()\n",
    "\n",
    "duration = 1\n",
    "interval = 120\n",
    "amount = 100\n",
    "\n",
    "trajs_low = Traffic.from_file(\n",
    "            f\"{home_path}/data/LSAGUAC/05_low_traffic/trajs_tma_low.parquet\"\n",
    "        )\n",
    "\n",
    "durations = [duration for i in range(amount)]\n",
    "intervals = [interval for i in range(amount)]\n",
    "trajectories = [trajs_low for i in range(amount)]\n",
    "\n",
    "t = [\n",
    "    (duras, intes, trajs)\n",
    "    for duras, intes, trajs in zip(durations, intervals, trajectories)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "# # Set the path to the folder containing the pkl files\n",
    "# folder_path = '/cluster/home/krum/github/VT2_airspace_complexity/data/LSAGUAC/07_cube_data/'\n",
    "\n",
    "# # Define the pattern to match the pkl files (i.e., files starting with \"range_18000\")\n",
    "# pattern = f\"{folder_path}/range_24000*.pkl\"\n",
    "\n",
    "# # Load the pkl files matching the pattern into a list\n",
    "# pkl_files = []\n",
    "# for file_path in glob.glob(pattern):\n",
    "#     with open(file_path, 'rb') as f:\n",
    "#         pkl_files.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = []\n",
    "lat_max = []\n",
    "lon_min = []\n",
    "lon_max = []\n",
    "alt_min = []\n",
    "alt_max = []\n",
    "\n",
    "count = []\n",
    "\n",
    "for cube in lsaguac.cubes:\n",
    "    lat_max.append(cube.lat_max)\n",
    "    lat_min.append(cube.lat_min)\n",
    "    lon_max.append(cube.lon_max)\n",
    "    lon_min.append(cube.lon_min)\n",
    "    alt_max.append(cube.alt_high)\n",
    "    alt_min.append(cube.alt_low)\n",
    "\n",
    "    with open(f'/cluster/home/krum/github/VT2_airspace_complexity/data/LSAGUAC/07_cube_data/{cube.id}_pairs.pkl', 'rb') as f:\n",
    "        count.append(len(pickle.load(f)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(\n",
    "    list(zip(lat_min, lat_max, lon_min, lon_max, alt_min, alt_max, count)),\n",
    "    columns=['lat_min', 'lat_max', 'lon_min', 'lon_max', 'alt_min', 'alt_max', 'count']\n",
    ")\n",
    "# get total of count column\n",
    "print(df['count'].sum())\n",
    "\n",
    "df = df[df.alt_min == 36000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read data/LSGACU/06_simulation/trajs_simulation.parquet\n",
    "# import pandas as pd\n",
    "# df = pd.read_parquet('/cluster/home/krum/github/VT2_airspace_complexity/data/LSAGUAC/06_simulation/trajs_simulation.parquet')\n",
    "# df.flight_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df by count\n",
    "df.sort_values(by=['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm_airspaces['LSAGUAC'].centroid.coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "fig = go.Figure(go.Scattermapbox())\n",
    "fig.update_layout(\n",
    "    mapbox_style=\"mapbox://styles/jakrum/clgqc6e8u00it01qzgtb4gg1z\",\n",
    "    mapbox_accesstoken='pk.eyJ1IjoiamFrcnVtIiwiYSI6ImNsZ3FjM3BiMzA3dzYzZHMzNHRkZnFtb3EifQ.ydDFlmylEcRCkRLWXqL1Cg',\n",
    "    showlegend=False,\n",
    "    height=1000,\n",
    "    width=1000,\n",
    "    margin={\"l\": 0, \"b\": 0, \"t\": 0, \"r\": 0},\n",
    "    mapbox_center_lat=nm_airspaces['LSAGUAC'].centroid.coords[0][1],\n",
    "    mapbox_center_lon=nm_airspaces['LSAGUAC'].centroid.coords[0][0],\n",
    "    mapbox_zoom=7,\n",
    "    # tickmode=\"array\",\n",
    "    # showticklabels=False,\n",
    ")\n",
    "\n",
    "# cmap = plt.cm.get_cmap('Blues')\n",
    "# norm = mcolors.Normalize(vmin=df['count'].min(), vmax=df['count'].max())\n",
    "cmap = cm.ScalarMappable(norm=Normalize(vmin=df['count'].min(), vmax=df['count'].max()), cmap='plasma')\n",
    "\n",
    "def colorscale(value):\n",
    "    color = cmap.to_rgba(value)\n",
    "    color = [int(c * 255) for c in color]\n",
    "    color_hex = '#{:02x}{:02x}{:02x}'.format(*color[:3])\n",
    "    return color_hex\n",
    "\n",
    "for row in df.iterrows():\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            lat=[row[1][0], row[1][0], row[1][1], row[1][1], row[1][0]],\n",
    "            lon=[row[1][2], row[1][3], row[1][3], row[1][2], row[1][2]],\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=2, color='black'),\n",
    "            fill=\"toself\",\n",
    "            fillcolor=colorscale(row[1][6]),\n",
    "            text=f\"count: {row[1][6]}\",\n",
    "            opacity=0.2,\n",
    "            name=\"Rectangle\",\n",
    "        )\n",
    "    )\n",
    "        # calculate center point of rectangle\n",
    "    center_lat = (row[1][0] + row[1][1]) / 2\n",
    "    center_lon = (row[1][2] + row[1][3]) / 2\n",
    "    # add count as text at center point\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            lat=[center_lat],\n",
    "            lon=[center_lon],\n",
    "            mode=\"text\",\n",
    "            text=[int(row[1][6])],\n",
    "            textfont=dict(size=8, color='grey'),\n",
    "            textposition=\"middle center\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add airspace shape to the plot\n",
    "lons, lats = nm_airspaces['LSAGUAC'].shape.exterior.xy\n",
    "trace = go.Scattermapbox(\n",
    "    mode=\"lines\",\n",
    "    lat=list(lats),\n",
    "    lon=list(lons),\n",
    "    line=dict(width=2, color=\"red\"),\n",
    ")\n",
    "\n",
    "colorbar_trace  = go.Scatter(x=[None],\n",
    "                             y=[None],\n",
    "                             mode='markers',\n",
    "                             marker=dict(\n",
    "                                 colorscale='plasma', \n",
    "                                 showscale=True,\n",
    "                                 cmin=df['count'].min(),\n",
    "                                 cmax=df['count'].max(),\n",
    "                                 colorbar=dict(thickness=20, outlinewidth=0, title='occurences')\n",
    "                             ),\n",
    "                             hoverinfo='none'\n",
    "                            )\n",
    "\n",
    "fig['layout']['showlegend'] = False\n",
    "fig.add_trace(colorbar_trace)\n",
    "\n",
    "# add figure title\n",
    "fig.update_layout(\n",
    "    title_text=\"Altitude level 36'000ft - 37'000ft\",\n",
    "    title_x=0.5,\n",
    "    margin={\"l\": 0, \"b\": 0, \"t\": 40, \"r\": 0},\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "\n",
    "fig.add_trace(trace)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row[1][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import GeoJson\n",
    "import pandas as pd\n",
    "from branca.colormap import linear\n",
    "\n",
    "# Create a folium map centered on the middle of the bounding box of the rectangles\n",
    "center_lat = (df['lat_min'].min() + df['lat_max'].max()) / 2\n",
    "center_lon = (df['lon_min'].min() + df['lon_max'].max()) / 2\n",
    "# m = folium.Map(location=[center_lat, center_lon], zoom_start=5)\n",
    "# m = folium.Map(location=[center_lat, center_lon], zoom_start=5, tiles='Stamen Toner Lite')\n",
    "m = folium.Map(\n",
    "    location=[center_lat, center_lon],\n",
    "    zoom_start=5,\n",
    "    tiles='https://stamen-tiles-{s}.a.ssl.fastly.net/toner-lite/{z}/{x}/{y}.png',\n",
    "    attr='Map data &copy; <a href=\"https://stamen.com/\">Stamen Design</a>'\n",
    ")\n",
    "\n",
    "colorscale = linear.YlOrRd_04.scale(df['count'].min(), df['count'].max())\n",
    "\n",
    "# Define a function to create a rectangle marker for each row in the dataframe\n",
    "def create_marker(row):\n",
    "    # Calculate the coordinates of the rectangle corners\n",
    "    lat1, lon1, lat2, lon2 = row['lat_min'], row['lon_min'], row['lat_max'], row['lon_max']\n",
    "    # Calculate the center of the rectangle\n",
    "    center_lat, center_lon = (lat1 + lat2) / 2, (lon1 + lon2) / 2\n",
    "    # Create a folium rectangle marker with the count as its color\n",
    "    folium.Rectangle(\n",
    "        bounds=[(lat1, lon1), (lat2, lon2)],\n",
    "        fill_color=colorscale(row['count']),  # set the color based on the count\n",
    "        # fill_color=f'#{int(row[\"count\"]):02x}0000'\n",
    "        fill_opacity=0.8,\n",
    "        color='black',\n",
    "        weight=0.5,\n",
    "        popup=f'Count: {row[\"count\"]}',\n",
    "        tooltip=f'Count: {row[\"count\"]}',\n",
    "        radius=0\n",
    "    ).add_to(m)\n",
    "\n",
    "# Apply the create_marker function to each row in the dataframe\n",
    "df.apply(create_marker, axis=1)\n",
    "\n",
    "# Show the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "# Define the layout of the map\n",
    "layout = go.Layout(\n",
    "    mapbox=dict(\n",
    "        center=dict(lat=center_lat, lon=center_lon),\n",
    "        style=\"carto-positron\",\n",
    "        zoom=5\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=0, b=0)\n",
    ")\n",
    "\n",
    "# Define the data for the rectangles\n",
    "data = [\n",
    "    go.Scattermapbox(\n",
    "        lat=[(row['lat_min'] + row['lat_max']) / 2 for _, row in df.iterrows()],\n",
    "        lon=[(row['lon_min'] + row['lon_max']) / 2 for _, row in df.iterrows()],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color=df['count'],\n",
    "            colorscale='YlOrRd',\n",
    "            cmin=df['count'].min(),\n",
    "            cmax=df['count'].max(),\n",
    "            opacity=0.8,\n",
    "            sizemode='area',\n",
    "            # sizeref=0.1,\n",
    "            # sizemin=2,\n",
    "            # sizemax=20,\n",
    "            # line=dict(\n",
    "            #     color='black',\n",
    "            #     width=0.5\n",
    "            # )\n",
    "        ),\n",
    "        hovertemplate='Count: %{marker.color}<extra></extra>',\n",
    "        name='Rectangles'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffic.core import Traffic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdmx\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_low = Traffic.from_file(\"../data/LSAGUAC/05_low_traffic/trajs_tma_low.parquet\")\n",
    "ids = trajs_low.flight_ids\n",
    "trajs_low_data = trajs_low.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 10\n",
    "freq = 5\n",
    "\n",
    "seconds = days * 24 * 60 * 60\n",
    "\n",
    "amount_deploys = seconds / freq\n",
    "\n",
    "timelist = []\n",
    "\n",
    "timer = 0\n",
    "for i in range(int(amount_deploys)):\n",
    "    timelist.append(timer)\n",
    "    timer = timer + freq\n",
    "\n",
    "indices = np.random.default_rng().choice(len(ids), len(timelist), replace=True)\n",
    "\n",
    "random_ids = np.array(ids)[indices]\n",
    "random_times = np.array(timelist)\n",
    "\n",
    "grouped = trajs_low_data.groupby('flight_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = []\n",
    "\n",
    "start_time = pd.Timestamp(\"2000-01-01 00:00:00\")\n",
    "\n",
    "for id, tm in tqdm(zip(random_ids, random_times), total=len(random_ids)):\n",
    "    traj_time = start_time + pd.Timedelta(seconds=tm)\n",
    "    temp = grouped.get_group(id)\n",
    "    timedelta = temp[\"timestamp\"] - temp[\"timestamp\"].iloc[0]\n",
    "    new_timestamp = traj_time + timedelta\n",
    "    timestring = str(new_timestamp.iloc[0].time())\n",
    "    flight_id = temp['flight_id'].iloc[0]\n",
    "    temp = temp[['latitude', 'longitude', 'altitude', 'icao24']]\n",
    "    temp.insert(0, \"timestamp\", new_timestamp)\n",
    "    temp.insert(1, \"flight_id\", flight_id + \"_\" + timestring)\n",
    "    df_all.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traf = pd.concat(df_all, axis=0).sort_values(by=['timestamp']).reset_index()\n",
    "df_traf.to_parquet(f\"../data/LSAGUAC/06_cube_data/simulation_trajs.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for cube in tqdm(lsaguac.cubes):\n",
    "    subset = df_traf.loc[(df_traf['latitude'] >= cube.lat_min) & \n",
    "                     (df_traf['latitude'] <= cube.lat_max) &\n",
    "                     (df_traf['longitude'] >= cube.lon_min) &\n",
    "                     (df_traf['longitude'] <= cube.lon_max) &\n",
    "                     (df_traf['altitude'] >= cube.alt_low) &\n",
    "                     (df_traf['altitude'] <= cube.alt_high)]\n",
    "    subset.to_parquet(f\"../data/LSAGUAC/06_cube_data/{cube.id}_trajs.parquet\", index=False)\n",
    "\n",
    "    in_out = (\n",
    "        subset.groupby(\"flight_id\")[\"timestamp\"]\n",
    "        .agg([\"min\", \"max\"])\n",
    "        .reset_index()\n",
    "        .sort_values(by=\"min\")\n",
    "        )\n",
    "    in_out.to_parquet(f\"../data/LSAGUAC/06_cube_data/{cube.id}_inout.parquet\", index=False)\n",
    "\n",
    "    df = in_out\n",
    "\n",
    "    count = 0\n",
    "    pairs = []\n",
    "\n",
    "    # Create a dictionary of flights indexed by their max value\n",
    "    flight_dict = {flight.max: [flight.flight_id] for flight in df.itertuples()}\n",
    "\n",
    "    # Find overlapping flights\n",
    "    pairs = []\n",
    "    count = 0\n",
    "    for flight in df.itertuples():\n",
    "        matches = []\n",
    "        for other_flight in flight_dict.get(flight.min, []):\n",
    "            if flight.max > df.loc[df[\"flight_id\"] == other_flight, \"min\"].values[0]:\n",
    "                matches.append(other_flight)\n",
    "                count += 1\n",
    "        if matches:\n",
    "            matches.append(flight.flight_id)\n",
    "            pairs.append(tuple(matches))\n",
    "\n",
    "    with open(f\"../data/LSAGUAC/06_cube_data/{cube.id}_pairs.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(pairs, fp)\n",
    "\n",
    "    print(f\"{cube.id} with {len(df)} flights with {len(pairs)} overlapping intervals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"../data/LSAGUAC/07_cube_data/range_24000_grid_59_pairs.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_all = pd.read_parquet(\"../data/LSAGUAC/06_simulation/trajs_simulation.parquet\")\n",
    "df_cube = pd.read_parquet(\"../data/LSAGUAC/07_cube_data/range_24000_grid_59_trajs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "id1 = 'EJU54ZH_37497_15:52:05'\n",
    "id2 = 'BCS24J_11403_15:54:05'\n",
    "\n",
    "fig = go.Figure(go.Scattermapbox())\n",
    "fig.update_layout(\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    showlegend=False,\n",
    "    height=800,\n",
    "    width=800,\n",
    "    margin={\"l\": 0, \"b\": 0, \"t\": 0, \"r\": 0},\n",
    "    # mapbox_center_lat=self.lat_cen,\n",
    "    # mapbox_center_lon=self.lon_cen,\n",
    "    mapbox_zoom=4,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"lines\",\n",
    "        lat=df_all[df_all.flight_id == id1].latitude,\n",
    "        lon=df_all[df_all.flight_id == id1].longitude,\n",
    "        text=df_all[df_all.flight_id == id1].timestamp,\n",
    "        line=dict(width=2, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"lines\",\n",
    "        lat=df_all[df_all.flight_id == id2].latitude,\n",
    "        lon=df_all[df_all.flight_id == id2].longitude,\n",
    "        text=df_all[df_all.flight_id == id2].timestamp,\n",
    "        line=dict(width=2, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"lines\",\n",
    "        lat=df_cube[df_cube.flight_id == id1].latitude,\n",
    "        lon=df_cube[df_cube.flight_id == id1].longitude,\n",
    "        text=df_cube[df_cube.flight_id == id1].timestamp,\n",
    "        line=dict(width=2, color=\"red\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"lines\",\n",
    "        lat=df_cube[df_cube.flight_id == id2].latitude,\n",
    "        lon=df_cube[df_cube.flight_id == id2].longitude,\n",
    "        text=df_cube[df_cube.flight_id == id2].timestamp,\n",
    "        line=dict(width=2, color=\"red\"),\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overlapping intervals\n",
    "mask = df[\"max\"].values[:, np.newaxis] > df[\"min\"].values[np.newaxis, :]\n",
    "mask &= np.triu(np.ones_like(mask), 1)\n",
    "\n",
    "# Get the flight ids for overlapping intervals\n",
    "i, j = np.nonzero(mask)\n",
    "pairs = [(df[\"flight_id\"][i[k]], df[\"flight_id\"][j[k]]) for k in range(len(i))]\n",
    "count = len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cube in tqdm(lsaguac.cubes):\n",
    "    subset = df_traf.loc[(df_traf['latitude'] >= cube.lat_min) & \n",
    "                     (df_traf['latitude'] <= cube.lat_max) &\n",
    "                     (df_traf['longitude'] >= cube.lon_min) &\n",
    "                     (df_traf['longitude'] <= cube.lon_max) &\n",
    "                     (df_traf['altitude'] >= cube.alt_low) &\n",
    "                     (df_traf['altitude'] <= cube.alt_high)]\n",
    "    subset.to_parquet(f\"../data/LSAGUAC/06_cube_data/{cube.id}_trajs.parquet\", index=False)\n",
    "\n",
    "    in_out = (\n",
    "        subset.groupby(\"flight_id\")[\"timestamp\"]\n",
    "        .agg([\"min\", \"max\"])\n",
    "        .reset_index()\n",
    "        .sort_values(by=\"min\")\n",
    "        )\n",
    "    in_out.to_parquet(f\"../data/LSAGUAC/06_cube_data/{cube.id}_inout.parquet\", index=False)\n",
    "\n",
    "    df = in_out\n",
    "\n",
    "    count = 0\n",
    "    pairs = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        matches = []\n",
    "        for j in range(i+1, len(df)):\n",
    "            # Check for overlapping intervals\n",
    "            if (df['max'][i] > df['min'][j]) and (df['max'][j] > df['min'][i]):\n",
    "                count += 1\n",
    "                matches.append(df['flight_id'][j])\n",
    "\n",
    "        if len(matches) > 0:\n",
    "            matches.append(df['flight_id'][i])\n",
    "            pairs.append(tuple(matches))\n",
    "\n",
    "    print(f'There were {len(df)} flights with {count} overlapping intervals.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsaguac.cubes[0].alt_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffic.core import Traffic\n",
    "\n",
    "trajs_low = Traffic.from_file(\"../data/LSAGUAC/05_low_traffic/trajs_tma_low.parquet\")\n",
    "trajs_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_low = (\n",
    "    trajs_low.resample(\"1s\")\n",
    "    .eval(desc=\"resampling\", max_workers=20)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsaguac.create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 100\n",
    "freq = 120\n",
    "\n",
    "\n",
    "seconds = days * 24 * 60 * 60\n",
    "\n",
    "for i in range(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "td = np.load('../data/LSAGUAC/06_training/X_norm.npy', allow_pickle=True)\n",
    "td = td.reshape(td.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from complexity.vae import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = VAE(\n",
    "    input_shape=(100, 5, 1),\n",
    "    conv_filters=[218, 12, 64],\n",
    "    conv_kernels=[3, 3, 3],\n",
    "    conv_strides=[1, 1, 1],\n",
    "    latent_space_dim=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    autoencoder.train(td, 32, 1)\n",
    "    autoencoder.save(save_folder='../data/LSAGUAC/07_model/model_test_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recondst, latent = autoencoder.reconstruct(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a txt file, separated by spaces\n",
    "with open('../data/LSAGUAC/06_training/normalisation.txt', 'r') as f:\n",
    "    data = f.readlines()[0]\n",
    "\n",
    "data = data.split(' ')\n",
    "data = [float(i) for i in data]\n",
    "lat_max = data[0]\n",
    "lat_min = data[1]\n",
    "lon_max = data[2]\n",
    "lon_min = data[3]\n",
    "alt_max = data[4]\n",
    "alt_min = data[5]\n",
    "gs_max = data[6]\n",
    "gs_min = data[7]\n",
    "tm_max = data[8]\n",
    "tm_min = data[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5\n",
    "\n",
    "lat_orig = td[x,:,0,:]\n",
    "lon_orig = td[x,:,1,:]\n",
    "alt_orig = td[x,:,2,:]\n",
    "gs_orig = td[x,:,3,:]\n",
    "tm_orig = td[x,:,4,:]\n",
    "\n",
    "lat_rec = recondst[x,:,0,:]\n",
    "lon_rec = recondst[x,:,1,:]\n",
    "alt_rec = recondst[x,:,2,:]\n",
    "gs_rec = recondst[x,:,3,:]\n",
    "tm_rec = recondst[x,:,4,:]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lon_orig, lat_orig)\n",
    "plt.plot(lon_rec, lat_rec)\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(alt_orig)\n",
    "plt.plot(alt_rec)\n",
    "plt.ylim(-1,1)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(gs_orig)\n",
    "plt.plot(gs_rec)\n",
    "plt.ylim(-1,1)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(tm_orig)\n",
    "plt.plot(tm_rec)\n",
    "# plt.ylim(-1,1)\n",
    "plt.show()\n",
    "\n",
    "# Assuming your data is stored in a variable called \"data\"\n",
    "pca = PCA(n_components=2)\n",
    "data_reduced = pca.fit_transform(latent)\n",
    "\n",
    "# Visualize the reduced data\n",
    "plt.scatter(data_reduced[:,0], data_reduced[:,1], s=1)\n",
    "plt.scatter(data_reduced[x,0], data_reduced[x,1], s=2, c='r')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(latent[:,0], latent[:,5], s=1)\n",
    "plt.scatter(latent[x,0], latent[x,5], s=1, c='r')\n",
    "plt.xlabel('Latent Component 1')\n",
    "plt.ylabel('Latent Component 2')\n",
    "plt.show()\n",
    "\n",
    "# tsne = TSNE(n_components=2)\n",
    "# data_reduced = tsne.fit_transform(latent)\n",
    "# plt.scatter(data_reduced[:,0], data_reduced[:,1], s=1)\n",
    "# plt.scatter(data_reduced[x,0], data_reduced[x,1], s=1, c='r')\n",
    "# plt.xlabel('t-SNE Component 1')\n",
    "# plt.ylabel('t-SNE Component 2')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# instantiate the DBSCAN algorithm\n",
    "dbscan = DBSCAN(eps=0.14, min_samples=10)\n",
    "\n",
    "# fit the model to the data\n",
    "dbscan.fit(latent)\n",
    "\n",
    "# retrieve the labels assigned to each point\n",
    "labels = dbscan.labels_\n",
    "\n",
    "# print the number of clusters found\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(f'Number of clusters: {n_clusters}')\n",
    "\n",
    "# print the labels assigned to each point\n",
    "print(f'Labels: {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe containing as columns the two principal components and labels\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data_reduced, columns=['PC1', 'PC2'])\n",
    "df['labels'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a scatterplot of the data colored by the assigned labels using seaborn\n",
    "import seaborn as sns\n",
    "sns.scatterplot(df, x='PC1', y='PC2', hue='labels', palette='Set1')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
