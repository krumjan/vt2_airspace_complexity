{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 07:49:03.743757: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 07:49:03.877903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-20 07:49:03.877926: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-20 07:49:05.259820: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 07:49:05.259895: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 07:49:05.259902: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n",
    "\n",
    "\n",
    "def _calculate_reconstruction_loss(y_target, y_predicted):\n",
    "    error = y_target - y_predicted\n",
    "    reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
    "    return reconstruction_loss\n",
    "\n",
    "\n",
    "def calculate_kl_loss(model):\n",
    "    # wrap `_calculate_kl_loss` such that it takes the model as an argument,\n",
    "    # returns a function which can take arbitrary number of arguments\n",
    "    # (for compatibility with `metrics` and utility in the loss function)\n",
    "    # and returns the kl loss\n",
    "    def _calculate_kl_loss(*args):\n",
    "        kl_loss = -0.5 * K.sum(1 + model.log_variance - K.square(model.mu) -\n",
    "                               K.exp(model.log_variance), axis=1)\n",
    "        return kl_loss\n",
    "    return _calculate_kl_loss\n",
    "\n",
    "\n",
    "class VAE:\n",
    "    \"\"\"\n",
    "    VAE represents a Deep Convolutional variational autoencoder architecture\n",
    "    with mirrored encoder and decoder components.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    "                 conv_filters,\n",
    "                 conv_kernels,\n",
    "                 conv_strides,\n",
    "                 latent_space_dim):\n",
    "        self.input_shape = input_shape # [28, 28, 1]\n",
    "        self.conv_filters = conv_filters # [2, 4, 8]\n",
    "        self.conv_kernels = conv_kernels # [3, 5, 3]\n",
    "        self.conv_strides = conv_strides # [1, 2, 2]\n",
    "        self.latent_space_dim = latent_space_dim # 2\n",
    "        self.reconstruction_loss_weight = 1000\n",
    "\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model = None\n",
    "\n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "        self._shape_before_bottleneck = None\n",
    "        self._model_input = None\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        self.model.summary()\n",
    "\n",
    "    def compile(self, learning_rate=0.0001):\n",
    "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(optimizer=optimizer,\n",
    "                           loss=self._calculate_combined_loss,\n",
    "                           metrics=[_calculate_reconstruction_loss,\n",
    "                                    calculate_kl_loss(self)])\n",
    "\n",
    "    def train(self, x_train, batch_size, num_epochs):\n",
    "        self.model.fit(x_train,\n",
    "                       x_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=num_epochs,\n",
    "                       shuffle=True)\n",
    "\n",
    "    def save(self, save_folder=\".\"):\n",
    "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
    "        self._save_parameters(save_folder)\n",
    "        self._save_weights(save_folder)\n",
    "\n",
    "    def load_weights(self, weights_path):\n",
    "        self.model.load_weights(weights_path)\n",
    "\n",
    "    def reconstruct(self, images):\n",
    "        latent_representations = self.encoder.predict(images)\n",
    "        reconstructed_images = self.decoder.predict(latent_representations)\n",
    "        return reconstructed_images, latent_representations\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, save_folder=\".\"):\n",
    "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(parameters_path, \"rb\") as f:\n",
    "            parameters = pickle.load(f)\n",
    "        autoencoder = VAE(*parameters)\n",
    "        weights_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        autoencoder.load_weights(weights_path)\n",
    "        return autoencoder\n",
    "\n",
    "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
    "        reconstruction_loss = _calculate_reconstruction_loss(y_target, y_predicted)\n",
    "        kl_loss = calculate_kl_loss(self)()\n",
    "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\\\n",
    "                                                         + kl_loss\n",
    "        return combined_loss\n",
    "\n",
    "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    def _save_parameters(self, save_folder):\n",
    "        parameters = [\n",
    "            self.input_shape,\n",
    "            self.conv_filters,\n",
    "            self.conv_kernels,\n",
    "            self.conv_strides,\n",
    "            self.latent_space_dim\n",
    "        ]\n",
    "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(parameters, f)\n",
    "\n",
    "    def _save_weights(self, save_folder):\n",
    "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        self.model.save_weights(save_path)\n",
    "\n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        model_input = self._model_input\n",
    "        model_output = self.decoder(self.encoder(model_input))\n",
    "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
    "\n",
    "    def _build_decoder(self):\n",
    "        decoder_input = self._add_decoder_input()\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "    def _add_decoder_input(self):\n",
    "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
    "\n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck) # [1, 2, 4] -> 8\n",
    "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
    "        return dense_layer\n",
    "\n",
    "    def _add_reshape_layer(self, dense_layer):\n",
    "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
    "\n",
    "    def _add_conv_transpose_layers(self, x):\n",
    "        \"\"\"Add conv transpose blocks.\"\"\"\n",
    "        # loop through all the conv layers in reverse order and stop at the\n",
    "        # first layer\n",
    "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
    "            x = self._add_conv_transpose_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_transpose_layer(self, layer_index, x):\n",
    "        layer_num = self._num_conv_layers - layer_index\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        x = ReLU(name=f\"decoder_relu_{layer_num}\")(x)\n",
    "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_decoder_output(self, x):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=1,\n",
    "            kernel_size=self.conv_kernels[0],\n",
    "            strides=self.conv_strides[0],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(x)\n",
    "        return output_layer\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self._model_input = encoder_input\n",
    "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
    "\n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
    "\n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        \"\"\"Create all convolutional blocks in encoder.\"\"\"\n",
    "        x = encoder_input\n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_layer(self, layer_index, x):\n",
    "        \"\"\"Add a convolutional block to a graph of layers, consisting of\n",
    "        conv 2d + ReLU + batch normalization.\n",
    "        \"\"\"\n",
    "        layer_number = layer_index + 1\n",
    "        conv_layer = Conv2D(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"encoder_conv_layer_{layer_number}\"\n",
    "        )\n",
    "        x = conv_layer(x)\n",
    "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
    "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_bottleneck(self, x):\n",
    "        \"\"\"Flatten data and add bottleneck with Guassian sampling (Dense\n",
    "        layer).\n",
    "        \"\"\"\n",
    "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
    "        x = Flatten()(x)\n",
    "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x)\n",
    "        self.log_variance = Dense(self.latent_space_dim,\n",
    "                                  name=\"log_variance\")(x)\n",
    "\n",
    "        def sample_point_from_normal_distribution(args):\n",
    "            mu, log_variance = args\n",
    "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,\n",
    "                                      stddev=1.)\n",
    "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
    "            return sampled_point\n",
    "\n",
    "        x = Lambda(sample_point_from_normal_distribution,\n",
    "                   name=\"encoder_output\")([self.mu, self.log_variance])\n",
    "        return x\n",
    "\n",
    "\n",
    "# LEARNING_RATE = 0.0005\n",
    "# BATCH_SIZE = 32\n",
    "# EPOCHS = 100\n",
    "\n",
    "\n",
    "# def load_mnist():\n",
    "#     (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#     x_train = x_train.astype(\"float32\") / 255\n",
    "#     x_train = x_train.reshape(x_train.shape + (1,))\n",
    "#     x_test = x_test.astype(\"float32\") / 255\n",
    "#     x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "#     return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "# def train(x_train, learning_rate, batch_size, epochs):\n",
    "#     autoencoder = VAE(\n",
    "#         input_shape=(28, 28, 1),\n",
    "#         conv_filters=(32, 64, 64, 64),\n",
    "#         conv_kernels=(3, 3, 3, 3),\n",
    "#         conv_strides=(1, 2, 2, 1),\n",
    "#         latent_space_dim=2\n",
    "#     )\n",
    "#     autoencoder.summary()\n",
    "#     autoencoder.compile(learning_rate)\n",
    "#     autoencoder.train(x_train, batch_size, epochs)\n",
    "#     return autoencoder\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     x_train, _, _, _ = load_mnist()\n",
    "#     autoencoder = train(x_train[:10000], LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
    "#     autoencoder.save(\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17541, 100, 3, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(f'data/rectangle_1/04_training_data/X_norm.npy', allow_pickle=True)\n",
    "data = data.reshape(data.shape + (1,))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 100, 3, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " encoder_conv_layer_1 (Conv2D)  (None, 100, 3, 32)   320         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " encoder_relu_1 (ReLU)          (None, 100, 3, 32)   0           ['encoder_conv_layer_1[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_1 (BatchNormalizati  (None, 100, 3, 32)  128         ['encoder_relu_1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_2 (Conv2D)  (None, 100, 3, 64)   18496       ['encoder_bn_1[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_2 (ReLU)          (None, 100, 3, 64)   0           ['encoder_conv_layer_2[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_2 (BatchNormalizati  (None, 100, 3, 64)  256         ['encoder_relu_2[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_3 (Conv2D)  (None, 100, 3, 64)   36928       ['encoder_bn_2[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_3 (ReLU)          (None, 100, 3, 64)   0           ['encoder_conv_layer_3[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_3 (BatchNormalizati  (None, 100, 3, 64)  256         ['encoder_relu_3[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_conv_layer_4 (Conv2D)  (None, 100, 3, 64)   36928       ['encoder_bn_3[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_relu_4 (ReLU)          (None, 100, 3, 64)   0           ['encoder_conv_layer_4[0][0]']   \n",
      "                                                                                                  \n",
      " encoder_bn_4 (BatchNormalizati  (None, 100, 3, 64)  256         ['encoder_relu_4[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 19200)        0           ['encoder_bn_4[0][0]']           \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 40)           768040      ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " log_variance (Dense)           (None, 40)           768040      ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " encoder_output (Lambda)        (None, 40)           0           ['mu[0][0]',                     \n",
      "                                                                  'log_variance[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,629,648\n",
      "Trainable params: 1,629,200\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 40)]              0         \n",
      "                                                                 \n",
      " decoder_dense (Dense)       (None, 19200)             787200    \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 100, 3, 64)        0         \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 100, 3, 64)       36928     \n",
      " r_1 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_relu_1 (ReLU)       (None, 100, 3, 64)        0         \n",
      "                                                                 \n",
      " decoder_bn_1 (BatchNormaliz  (None, 100, 3, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 100, 3, 64)       36928     \n",
      " r_2 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_relu_2 (ReLU)       (None, 100, 3, 64)        0         \n",
      "                                                                 \n",
      " decoder_bn_2 (BatchNormaliz  (None, 100, 3, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 100, 3, 64)       36928     \n",
      " r_3 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " decoder_relu_3 (ReLU)       (None, 100, 3, 64)        0         \n",
      "                                                                 \n",
      " decoder_bn_3 (BatchNormaliz  (None, 100, 3, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " decoder_conv_transpose_laye  (None, 100, 3, 1)        577       \n",
      " r_4 (Conv2DTranspose)                                           \n",
      "                                                                 \n",
      " sigmoid_layer (Activation)  (None, 100, 3, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 899,329\n",
      "Trainable params: 898,945\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 100, 3, 1)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 40)                1629648   \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 100, 3, 1)         899329    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,528,977\n",
      "Trainable params: 2,528,145\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = VAE(\n",
    "    input_shape=(100, 3, 1),\n",
    "    conv_filters=[32, 64, 64, 32],\n",
    "    conv_kernels=[3, 3, 3, 3],\n",
    "    conv_strides=[1, 1, 1, 1],\n",
    "    latent_space_dim=32\n",
    ")\n",
    "autoencoder.summary()\n",
    "\n",
    "# original:\n",
    "# autoencoder = VAE(\n",
    "#     input_shape=(100, 3, 1),\n",
    "#     conv_filters=[32, 64, 64, 64],\n",
    "#     conv_kernels=[3, 3, 3, 3],\n",
    "#     conv_strides=[1, 1, 1, 1],\n",
    "#     latent_space_dim=32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 08:08:13.716292: W tensorflow/c/c_api.cc:291] Operation '{name:'encoder_bn_1_6/beta/Assign' id:10385 op device:{requested: '', assigned: ''} def:{{{node encoder_bn_1_6/beta/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](encoder_bn_1_6/beta, encoder_bn_1_6/beta/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "autoencoder = autoencoder.load(\"model/model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17541 samples\n",
      "Epoch 1/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5483 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7528\n",
      "Epoch 2/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5297 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7314\n",
      "Epoch 3/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5530 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7466\n",
      "Epoch 4/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5676 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7554\n",
      "Epoch 5/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5252 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7286\n",
      "Epoch 6/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5754 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7636\n",
      "Epoch 7/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5556 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7335\n",
      "Epoch 8/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5483 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7414\n",
      "Epoch 9/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5265 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7324\n",
      "Epoch 10/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5598 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7497\n",
      "Epoch 11/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5465 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7518\n",
      "Epoch 12/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5572 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7547\n",
      "Epoch 13/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.6182 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7962\n",
      "Epoch 14/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5460 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7391\n",
      "Epoch 15/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5568 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7507\n",
      "Epoch 16/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5520 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7431\n",
      "Epoch 17/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5363 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7350\n",
      "Epoch 18/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5621 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7598\n",
      "Epoch 19/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5399 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7449\n",
      "Epoch 20/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5535 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7487\n",
      "Epoch 21/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5570 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7492\n",
      "Epoch 22/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5548 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7452\n",
      "Epoch 23/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5454 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7327\n",
      "Epoch 24/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5591 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7593\n",
      "Epoch 25/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5515 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7345\n",
      "Epoch 26/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5503 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7527\n",
      "Epoch 27/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5601 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7650\n",
      "Epoch 28/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5405 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7316\n",
      "Epoch 29/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5519 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7567\n",
      "Epoch 30/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5786 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7794\n",
      "Epoch 31/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5618 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7554\n",
      "Epoch 32/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5476 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7443\n",
      "Epoch 33/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5389 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7448\n",
      "Epoch 34/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5443 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7400\n",
      "Epoch 35/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5615 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7488\n",
      "Epoch 36/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5198 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7243\n",
      "Epoch 37/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5431 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7382\n",
      "Epoch 38/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5560 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7488\n",
      "Epoch 39/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5367 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7442\n",
      "Epoch 40/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5432 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7406\n",
      "Epoch 41/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5738 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7585\n",
      "Epoch 42/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5404 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7411\n",
      "Epoch 43/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5150 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7217\n",
      "Epoch 44/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5471 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7335\n",
      "Epoch 45/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5487 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7402\n",
      "Epoch 46/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5508 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7459\n",
      "Epoch 47/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5392 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7339\n",
      "Epoch 48/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5496 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7456\n",
      "Epoch 49/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5626 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7553\n",
      "Epoch 50/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5640 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7694\n",
      "Epoch 51/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5359 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7360\n",
      "Epoch 52/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5424 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7423\n",
      "Epoch 53/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5541 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7581\n",
      "Epoch 54/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5592 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7719\n",
      "Epoch 55/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5373 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7294\n",
      "Epoch 56/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5765 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7705\n",
      "Epoch 57/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5186 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7302\n",
      "Epoch 58/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5045 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7057\n",
      "Epoch 59/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5391 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7345\n",
      "Epoch 60/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5389 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7492\n",
      "Epoch 61/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5574 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7551\n",
      "Epoch 62/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5672 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7630\n",
      "Epoch 63/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5627 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7765\n",
      "Epoch 64/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5588 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7577\n",
      "Epoch 65/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5368 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7326\n",
      "Epoch 66/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5707 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7753\n",
      "Epoch 67/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5407 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7366\n",
      "Epoch 68/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5647 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7721\n",
      "Epoch 69/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5591 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7625\n",
      "Epoch 70/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5652 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7566\n",
      "Epoch 71/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5032 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7090\n",
      "Epoch 72/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5489 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7497\n",
      "Epoch 73/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5455 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7423\n",
      "Epoch 74/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5097 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7147\n",
      "Epoch 75/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5448 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7376\n",
      "Epoch 76/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5263 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7267\n",
      "Epoch 77/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5715 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7739\n",
      "Epoch 78/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5461 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7467\n",
      "Epoch 79/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5429 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7473\n",
      "Epoch 80/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5442 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7294\n",
      "Epoch 81/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.6112 - _calculate_reconstruction_loss: 0.0019 - _calculate_kl_loss: 4.7577\n",
      "Epoch 82/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5479 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7648\n",
      "Epoch 83/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5362 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7395\n",
      "Epoch 84/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5256 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7306\n",
      "Epoch 85/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5450 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7480\n",
      "Epoch 86/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5322 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7371\n",
      "Epoch 87/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5664 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7471\n",
      "Epoch 88/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5522 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7636\n",
      "Epoch 89/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5532 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7586\n",
      "Epoch 90/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5449 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7449\n",
      "Epoch 91/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5414 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7379\n",
      "Epoch 92/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5613 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7772\n",
      "Epoch 93/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5547 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7482\n",
      "Epoch 94/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5161 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7270\n",
      "Epoch 95/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5391 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7330\n",
      "Epoch 96/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5228 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7477\n",
      "Epoch 97/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5647 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7740\n",
      "Epoch 98/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5402 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7459\n",
      "Epoch 99/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5250 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7272\n",
      "Epoch 100/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5407 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7580\n",
      "Epoch 101/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5625 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7465\n",
      "Epoch 102/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5381 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7411\n",
      "Epoch 103/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5391 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7356\n",
      "Epoch 104/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5422 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7532\n",
      "Epoch 105/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.6414 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.8148\n",
      "Epoch 106/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.6665 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.8176\n",
      "Epoch 107/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5652 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7759\n",
      "Epoch 108/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5496 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7766\n",
      "Epoch 109/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5572 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7816\n",
      "Epoch 110/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5129 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7253\n",
      "Epoch 111/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5253 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7471\n",
      "Epoch 112/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5362 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7476\n",
      "Epoch 113/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5137 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7363\n",
      "Epoch 114/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5342 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7437\n",
      "Epoch 115/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5319 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7511\n",
      "Epoch 116/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5255 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7310\n",
      "Epoch 117/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5044 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7205\n",
      "Epoch 118/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5569 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7718\n",
      "Epoch 119/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5482 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7566\n",
      "Epoch 120/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5331 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7407\n",
      "Epoch 121/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5308 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7350\n",
      "Epoch 122/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5551 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7584\n",
      "Epoch 123/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5352 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7371\n",
      "Epoch 124/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5232 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7282\n",
      "Epoch 125/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5419 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7385\n",
      "Epoch 126/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5396 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7339\n",
      "Epoch 127/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5479 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7612\n",
      "Epoch 128/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5348 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7411\n",
      "Epoch 129/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5187 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7186\n",
      "Epoch 130/1000\n",
      "17541/17541 [==============================] - 26s 2ms/sample - loss: 6.5388 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7572\n",
      "Epoch 131/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5465 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7489\n",
      "Epoch 132/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5503 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7463\n",
      "Epoch 133/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5577 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7535\n",
      "Epoch 134/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5361 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7397\n",
      "Epoch 135/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5445 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7458\n",
      "Epoch 136/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5531 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7535\n",
      "Epoch 137/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5500 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7598\n",
      "Epoch 138/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5583 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7702\n",
      "Epoch 139/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5321 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7471\n",
      "Epoch 140/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5411 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7488\n",
      "Epoch 141/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5428 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7623\n",
      "Epoch 142/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5460 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7587\n",
      "Epoch 143/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5431 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7549\n",
      "Epoch 144/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5367 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7417\n",
      "Epoch 145/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5518 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7741\n",
      "Epoch 146/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5471 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7486\n",
      "Epoch 147/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5128 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7297\n",
      "Epoch 148/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5345 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7324\n",
      "Epoch 149/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5440 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7518\n",
      "Epoch 150/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5393 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7508\n",
      "Epoch 151/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5271 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7325\n",
      "Epoch 152/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5197 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7372\n",
      "Epoch 153/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5624 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7720\n",
      "Epoch 154/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5295 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7392\n",
      "Epoch 155/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5358 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7395\n",
      "Epoch 156/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5435 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7468\n",
      "Epoch 157/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5268 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7351\n",
      "Epoch 158/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5208 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7323\n",
      "Epoch 159/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5329 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7434\n",
      "Epoch 160/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5658 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7585\n",
      "Epoch 161/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5277 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7295\n",
      "Epoch 162/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5526 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7669\n",
      "Epoch 163/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5511 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7578\n",
      "Epoch 164/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5473 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7485\n",
      "Epoch 165/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5535 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7492\n",
      "Epoch 166/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5360 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7330\n",
      "Epoch 167/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5340 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7536\n",
      "Epoch 168/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5217 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7277\n",
      "Epoch 169/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5420 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7542\n",
      "Epoch 170/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5438 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7444\n",
      "Epoch 171/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5472 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7711\n",
      "Epoch 172/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5760 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7921\n",
      "Epoch 173/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5190 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7350\n",
      "Epoch 174/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5486 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7547\n",
      "Epoch 175/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5235 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7357\n",
      "Epoch 176/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5332 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7500\n",
      "Epoch 177/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5668 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7841\n",
      "Epoch 178/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5412 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7496\n",
      "Epoch 179/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5268 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7483\n",
      "Epoch 180/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5244 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7423\n",
      "Epoch 181/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5415 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7530\n",
      "Epoch 182/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5290 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7450\n",
      "Epoch 183/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5470 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7738\n",
      "Epoch 184/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5321 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7435\n",
      "Epoch 185/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5288 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7356\n",
      "Epoch 186/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5428 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7443\n",
      "Epoch 187/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5357 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7497\n",
      "Epoch 188/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5388 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7588\n",
      "Epoch 189/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5304 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7551\n",
      "Epoch 190/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5045 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7147\n",
      "Epoch 191/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5288 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7415\n",
      "Epoch 192/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5383 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7371\n",
      "Epoch 193/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5132 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7180\n",
      "Epoch 194/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5376 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7529\n",
      "Epoch 195/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5566 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7706\n",
      "Epoch 196/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5123 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7286\n",
      "Epoch 197/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5219 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7313\n",
      "Epoch 198/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5267 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7375\n",
      "Epoch 199/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5154 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7277\n",
      "Epoch 200/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5096 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7288\n",
      "Epoch 201/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5247 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7347\n",
      "Epoch 202/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5312 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7308\n",
      "Epoch 203/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5322 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7503\n",
      "Epoch 204/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5255 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7437\n",
      "Epoch 205/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5247 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7359\n",
      "Epoch 206/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5049 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7195\n",
      "Epoch 207/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5483 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7651\n",
      "Epoch 208/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5340 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7623\n",
      "Epoch 209/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5370 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7470\n",
      "Epoch 210/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5361 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7559\n",
      "Epoch 211/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5373 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7506\n",
      "Epoch 212/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5348 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7584\n",
      "Epoch 213/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5139 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7295\n",
      "Epoch 214/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5448 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7451\n",
      "Epoch 215/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5466 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7640\n",
      "Epoch 216/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5495 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7658\n",
      "Epoch 217/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5242 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7420\n",
      "Epoch 218/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5302 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7364\n",
      "Epoch 219/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5309 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7496\n",
      "Epoch 220/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5185 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7352\n",
      "Epoch 221/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5239 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7373\n",
      "Epoch 222/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5062 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7130\n",
      "Epoch 223/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5363 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7569\n",
      "Epoch 224/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5055 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7139\n",
      "Epoch 225/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5483 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7553\n",
      "Epoch 226/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5156 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7289\n",
      "Epoch 227/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5181 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7223\n",
      "Epoch 228/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5459 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7571\n",
      "Epoch 229/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5036 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7245\n",
      "Epoch 230/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5287 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7316\n",
      "Epoch 231/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5080 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7406\n",
      "Epoch 232/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5447 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7583\n",
      "Epoch 233/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5145 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7424\n",
      "Epoch 234/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5196 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7322\n",
      "Epoch 235/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.4912 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7024\n",
      "Epoch 236/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5252 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7537\n",
      "Epoch 237/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5257 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7417\n",
      "Epoch 238/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5013 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7247\n",
      "Epoch 239/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5240 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7434\n",
      "Epoch 240/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5109 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7332\n",
      "Epoch 241/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5424 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7468\n",
      "Epoch 242/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5090 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7321\n",
      "Epoch 243/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5253 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7476\n",
      "Epoch 244/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5114 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7312\n",
      "Epoch 245/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5471 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7615\n",
      "Epoch 246/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5184 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7269\n",
      "Epoch 247/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5367 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7522\n",
      "Epoch 248/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.4859 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7141\n",
      "Epoch 249/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5357 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7430\n",
      "Epoch 250/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5052 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7192\n",
      "Epoch 251/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5338 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7488\n",
      "Epoch 252/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5420 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7535\n",
      "Epoch 253/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5311 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7528\n",
      "Epoch 254/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5338 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7534\n",
      "Epoch 255/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5333 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7477\n",
      "Epoch 256/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5207 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7301\n",
      "Epoch 257/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5203 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7398\n",
      "Epoch 258/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5485 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7798\n",
      "Epoch 259/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5058 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7266\n",
      "Epoch 260/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5196 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7381\n",
      "Epoch 261/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5514 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7645\n",
      "Epoch 262/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5287 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7498\n",
      "Epoch 263/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5152 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7334\n",
      "Epoch 264/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5317 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7449\n",
      "Epoch 265/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.4954 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7150\n",
      "Epoch 266/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5259 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7471\n",
      "Epoch 267/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5120 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7251\n",
      "Epoch 268/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5339 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7565\n",
      "Epoch 269/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5256 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7437\n",
      "Epoch 270/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5351 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7665\n",
      "Epoch 271/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5335 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7477\n",
      "Epoch 272/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5305 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7585\n",
      "Epoch 273/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5359 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7432\n",
      "Epoch 274/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5353 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7566\n",
      "Epoch 275/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5275 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7464\n",
      "Epoch 276/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5180 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7468\n",
      "Epoch 277/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5406 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7591\n",
      "Epoch 278/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5122 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7310\n",
      "Epoch 279/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5327 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7678\n",
      "Epoch 280/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5078 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7302\n",
      "Epoch 281/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5563 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7598\n",
      "Epoch 282/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5208 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7479\n",
      "Epoch 283/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5492 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7492\n",
      "Epoch 284/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5657 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7819\n",
      "Epoch 285/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5134 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7333\n",
      "Epoch 286/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5367 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7493\n",
      "Epoch 287/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5445 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7706\n",
      "Epoch 288/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5452 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7677\n",
      "Epoch 289/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5076 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7235\n",
      "Epoch 290/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.4972 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7189\n",
      "Epoch 291/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5414 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7474\n",
      "Epoch 292/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5415 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7701\n",
      "Epoch 293/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5319 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7498\n",
      "Epoch 294/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5383 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7439\n",
      "Epoch 295/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5252 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7385\n",
      "Epoch 296/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5230 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7404\n",
      "Epoch 297/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5283 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7396\n",
      "Epoch 298/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5231 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7468\n",
      "Epoch 299/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5173 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7289\n",
      "Epoch 300/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5020 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7116\n",
      "Epoch 301/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5156 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7363\n",
      "Epoch 302/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5268 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7482\n",
      "Epoch 303/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5430 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7582\n",
      "Epoch 304/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5190 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7370\n",
      "Epoch 305/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5405 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7590\n",
      "Epoch 306/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5027 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7207\n",
      "Epoch 307/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5091 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7379\n",
      "Epoch 308/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5118 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7401\n",
      "Epoch 309/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5202 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7406\n",
      "Epoch 310/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5091 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7290\n",
      "Epoch 311/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5302 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7392\n",
      "Epoch 312/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5122 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7239\n",
      "Epoch 313/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5294 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7611\n",
      "Epoch 314/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5057 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7298\n",
      "Epoch 315/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5103 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7520\n",
      "Epoch 316/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5389 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7639\n",
      "Epoch 317/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5156 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7290\n",
      "Epoch 318/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5222 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7453\n",
      "Epoch 319/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5240 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7414\n",
      "Epoch 320/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5252 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7511\n",
      "Epoch 321/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5092 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7246\n",
      "Epoch 322/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.5387 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7569\n",
      "Epoch 323/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5262 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7742\n",
      "Epoch 324/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5134 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7291\n",
      "Epoch 325/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5139 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7511\n",
      "Epoch 326/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5148 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7333\n",
      "Epoch 327/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5169 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7321\n",
      "Epoch 328/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5069 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7352\n",
      "Epoch 329/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5361 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7568\n",
      "Epoch 330/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5221 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7421\n",
      "Epoch 331/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5010 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7212\n",
      "Epoch 332/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5195 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7422\n",
      "Epoch 333/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5197 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7438\n",
      "Epoch 334/1000\n",
      "17541/17541 [==============================] - 23s 1ms/sample - loss: 6.4965 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7098\n",
      "Epoch 335/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5105 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7264\n",
      "Epoch 336/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5310 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7461\n",
      "Epoch 337/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5275 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7497\n",
      "Epoch 338/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5138 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7351\n",
      "Epoch 339/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5039 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7295\n",
      "Epoch 340/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5136 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7373\n",
      "Epoch 341/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5267 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7422\n",
      "Epoch 342/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5216 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7444\n",
      "Epoch 343/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.4850 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7157\n",
      "Epoch 344/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5074 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7086\n",
      "Epoch 345/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5168 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7401\n",
      "Epoch 346/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5056 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7333\n",
      "Epoch 347/1000\n",
      "17541/17541 [==============================] - 26s 1ms/sample - loss: 6.5178 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7533\n",
      "Epoch 348/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5064 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7298\n",
      "Epoch 349/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5105 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7412\n",
      "Epoch 350/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5234 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7370\n",
      "Epoch 351/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5070 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7319\n",
      "Epoch 352/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5029 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7341\n",
      "Epoch 353/1000\n",
      "17541/17541 [==============================] - 25s 1ms/sample - loss: 6.5387 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7555\n",
      "Epoch 354/1000\n",
      "17541/17541 [==============================] - 24s 1ms/sample - loss: 6.5344 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7552\n",
      "Epoch 355/1000\n",
      "13824/17541 [======================>.......] - ETA: 5s - loss: 6.5385 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 4.7544"
     ]
    }
   ],
   "source": [
    "autoencoder.train(data, 32, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(save_folder=\"model/model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "recondst, latent = autoencoder.reconstruct(flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 12650\n",
    "\n",
    "lat_orig = flight[x,:,0,:]\n",
    "lon_orig = flight[x,:,1,:]\n",
    "alt_orig = flight[x,:,2,:]\n",
    "\n",
    "lat_rec = recondst[x,:,0,:]\n",
    "lon_rec = recondst[x,:,1,:]\n",
    "alt_rec = recondst[x,:,2,:]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lon_orig, lat_orig)\n",
    "plt.plot(lon_rec, lat_rec)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(alt_orig)\n",
    "plt.plot(alt_rec)\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
